{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5b7197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "45597088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30691</th>\n",
       "      <td>29 august 1821</td>\n",
       "      <td>1821-08-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5954</th>\n",
       "      <td>saturday 1 august 2048</td>\n",
       "      <td>2048-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21163</th>\n",
       "      <td>1887 15 july</td>\n",
       "      <td>1887-07-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8970</th>\n",
       "      <td>1745 4 feb</td>\n",
       "      <td>1745-02-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>sun 1810 25 february</td>\n",
       "      <td>1810-02-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24784</th>\n",
       "      <td>sat 8 aug 1570</td>\n",
       "      <td>1570-08-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34528</th>\n",
       "      <td>dec 28 1687</td>\n",
       "      <td>1687-12-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8375</th>\n",
       "      <td>mar 22 1553</td>\n",
       "      <td>1553-03-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32271</th>\n",
       "      <td>august 29 1768</td>\n",
       "      <td>1768-08-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20244</th>\n",
       "      <td>1729 1 january</td>\n",
       "      <td>1730-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33468</th>\n",
       "      <td>sunday november 18 1528</td>\n",
       "      <td>1528-11-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13059</th>\n",
       "      <td>feb 27 1651</td>\n",
       "      <td>1651-02-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20643</th>\n",
       "      <td>wednesday november 24 2032</td>\n",
       "      <td>2032-11-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35108</th>\n",
       "      <td>thursday january 17 1924</td>\n",
       "      <td>1924-01-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17132</th>\n",
       "      <td>fri 5 feb 1745</td>\n",
       "      <td>1745-02-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>21 may 1746</td>\n",
       "      <td>1746-05-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>dec 13 1960</td>\n",
       "      <td>1960-12-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10235</th>\n",
       "      <td>feb 24 1598</td>\n",
       "      <td>1598-02-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38981</th>\n",
       "      <td>feb 25 1695</td>\n",
       "      <td>1695-02-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21735</th>\n",
       "      <td>jul 17 1608</td>\n",
       "      <td>1608-07-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           source      target\n",
       "30691              29 august 1821  1821-08-29\n",
       "5954       saturday 1 august 2048  2048-08-01\n",
       "21163                1887 15 july  1887-07-15\n",
       "8970                   1745 4 feb  1745-02-04\n",
       "315          sun 1810 25 february  1810-02-25\n",
       "24784              sat 8 aug 1570  1570-08-08\n",
       "34528                 dec 28 1687  1687-12-28\n",
       "8375                  mar 22 1553  1553-03-22\n",
       "32271              august 29 1768  1768-08-29\n",
       "20244              1729 1 january  1730-01-01\n",
       "33468     sunday november 18 1528  1528-11-18\n",
       "13059                 feb 27 1651  1651-02-27\n",
       "20643  wednesday november 24 2032  2032-11-24\n",
       "35108    thursday january 17 1924  1924-01-17\n",
       "17132              fri 5 feb 1745  1745-02-05\n",
       "74                    21 may 1746  1746-05-21\n",
       "573                   dec 13 1960  1960-12-13\n",
       "10235                 feb 24 1598  1598-02-24\n",
       "38981                 feb 25 1695  1695-02-25\n",
       "21735                 jul 17 1608  1608-07-17"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_PATH = \"dataset/Assignment2aDataset.txt\"\n",
    "df = pd.read_csv(DATASET_PATH, names = [\"source\", \"target\"])\n",
    "df[\"source\"] = df[\"source\"].apply(lambda x: x.strip()[1:-1].replace(\"/\", \"-\"))\n",
    "df[\"target\"] = df[\"target\"].apply(lambda x: x.strip()[1:-1])\n",
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f41536e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32823</th>\n",
       "      <td>9 september 1943</td>\n",
       "      <td>1943-09-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16298</th>\n",
       "      <td>may 23 1532</td>\n",
       "      <td>1532-05-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28505</th>\n",
       "      <td>june 27 1908</td>\n",
       "      <td>1908-06-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6689</th>\n",
       "      <td>july 24 1766</td>\n",
       "      <td>1766-07-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26893</th>\n",
       "      <td>december 26 2008</td>\n",
       "      <td>2008-12-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19536</th>\n",
       "      <td>tuesday june 4 1669</td>\n",
       "      <td>1669-06-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13332</th>\n",
       "      <td>2034 25 august</td>\n",
       "      <td>2034-08-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18523</th>\n",
       "      <td>sat 1983 29 january</td>\n",
       "      <td>1983-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14835</th>\n",
       "      <td>sunday march 15 1857</td>\n",
       "      <td>1857-03-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8445</th>\n",
       "      <td>16 july 2030</td>\n",
       "      <td>2030-07-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     source      target\n",
       "32823      9 september 1943  1943-09-09\n",
       "16298           may 23 1532  1532-05-23\n",
       "28505          june 27 1908  1908-06-27\n",
       "6689           july 24 1766  1766-07-24\n",
       "26893      december 26 2008  2008-12-26\n",
       "...                     ...         ...\n",
       "19536   tuesday june 4 1669  1669-06-04\n",
       "13332        2034 25 august  2034-08-25\n",
       "18523   sat 1983 29 january  1983-01-29\n",
       "14835  sunday march 15 1857  1857-03-15\n",
       "8445           16 july 2030  2030-07-16\n",
       "\n",
       "[4000 rows x 2 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, random_state=42, test_size=0.1)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9788d00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6d2f19d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 may 20 2034\n",
       "1                  9 may 1630\n",
       "2                  15-03-2014\n",
       "3                 mar 16 1675\n",
       "4                 jun 16 1640\n",
       "                 ...         \n",
       "39995        december 26 1900\n",
       "39996             15 may 1828\n",
       "39997    friday april 18 1851\n",
       "39998            june 11 2070\n",
       "39999         january 27 1712\n",
       "Name: source, Length: 40000, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"source\"].apply(lambda x: x.replace(\"/\", \"-\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "774c0c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import vocab\n",
    "from torchtext.utils import download_from_url, extract_archive\n",
    "import io\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0e49fd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tokenizer = get_tokenizer('spacy', language='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f7eea69c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10/09/2023']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(\"10/09/2023\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fc5b2925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22099          [sunday, 1574, 25, 08]\n",
       "7321              [1548, 7, february]\n",
       "2452             [december, 25, 1605]\n",
       "29726        [thursday, 1866, 27, 09]\n",
       "22291     [thursday, august, 6, 1863]\n",
       "4793       [tue, 1963, 24, september]\n",
       "35032                  [1975, 4, mar]\n",
       "34344                 [july, 7, 1664]\n",
       "32997              [january, 9, 1617]\n",
       "33772    [monday, november, 17, 1681]\n",
       "Name: source, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"source\"].sample(10).apply(lambda x: en_tokenizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "55d448fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5688     [1966, -, 07, -, 13]\n",
       "26568    [1804, -, 03, -, 20]\n",
       "22744    [1715, -, 01, -, 25]\n",
       "3295     [1832, -, 05, -, 26]\n",
       "32054    [1999, -, 10, -, 14]\n",
       "21620    [1618, -, 07, -, 13]\n",
       "19823    [1746, -, 04, -, 16]\n",
       "28567    [1994, -, 01, -, 04]\n",
       "11668    [1646, -, 12, -, 01]\n",
       "34859    [2063, -, 01, -, 26]\n",
       "Name: target, dtype: object"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"target\"].sample(10).apply(lambda x: en_tokenizer(x.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "50e64982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all have 5 length\n",
    "df[\"target\"].apply(lambda x: len(en_tokenizer(x.strip())) != 5).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d58c9367",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter() # dict of {token: Freq}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "362b2bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for source in df[\"source\"]:\n",
    "    counter.update(en_tokenizer(source))\n",
    "\n",
    "for source in df[\"target\"]:\n",
    "    counter.update(en_tokenizer(source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "79b1ff9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = vocab(counter, specials=['<unk>', '<pad>', '<bos>', '<eos>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2d5bd342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc[\"november\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "79e98ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding\n",
    "PAD_IDX = voc['<pad>']\n",
    "BOS_IDX = voc['<bos>']\n",
    "EOS_IDX = voc['<eos>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "273097b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4, 5, 6]), tensor([  6,  10, 478,  10,   5]))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "for (source, target) in zip(df[\"source\"], df[\"target\"]):\n",
    "    s_tensor_ = torch.tensor([voc[token] for token in en_tokenizer(source)])\n",
    "    t_tensor_ = torch.tensor([voc[token] for token in en_tokenizer(target)])\n",
    "    data.append((s_tensor_, t_tensor_))\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2ad514ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ac6ca451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karm/miniconda3/envs/torch310/lib/python3.11/site-packages/torchtext/data/utils.py:105: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "class DateDataset(Dataset):\n",
    "    def __init__(self, DATASET_PATH = \"dataset/Assignment2aDataset.txt\", split=\"train\"):\n",
    "        df = pd.read_csv(DATASET_PATH, names = [\"source\", \"target\"])\n",
    "        df[\"source\"] = df[\"source\"].apply(lambda x: x.strip()[1:-1].replace(\"/\", \"-\"))\n",
    "        df[\"target\"] = df[\"target\"].apply(lambda x: x.strip()[1:-1])\n",
    "        df_train, df_test = train_test_split(df, random_state=42, test_size=0.1)\n",
    "        \n",
    "        # tokenize\n",
    "        en_tokenizer = get_tokenizer('spacy', language='en')   \n",
    "        counter = Counter() # dict of {token: Freq}     \n",
    "        for source in df[\"source\"]:\n",
    "            counter.update(en_tokenizer(source))\n",
    "\n",
    "        for source in df[\"target\"]:\n",
    "            counter.update(en_tokenizer(source))\n",
    "        \n",
    "        voc = vocab(counter, specials=['<unk>', '<pad>', '<bos>', '<eos>'])    \n",
    "        \n",
    "        # create data\n",
    "        if split == \"train\":\n",
    "            self.data_df = df_train\n",
    "        else:\n",
    "            self.data_df = df_test\n",
    "            \n",
    "        data = []\n",
    "        for (source, target) in zip(self.data_df[\"source\"], self.data_df[\"target\"]):\n",
    "            s_tensor_ = torch.tensor([voc[token] for token in en_tokenizer(source)])\n",
    "            t_tensor_ = torch.tensor([voc[token] for token in en_tokenizer(target)])\n",
    "            data.append((s_tensor_, t_tensor_))\n",
    "        \n",
    "        self.voc = voc\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "train_dataset = DateDataset(split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f58eb36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS_IDX = train_dataset.voc[\"<bos>\"]\n",
    "EOS_IDX = train_dataset.voc[\"<eos>\"]\n",
    "PAD_IDX = train_dataset.voc[\"<pad>\"]\n",
    "\n",
    "def generate_batch(data_batch):\n",
    "    s_batch, t_batch = [], []\n",
    "    for (s_item, t_item) in data_batch:\n",
    "        s_batch.append(torch.cat([torch.tensor([BOS_IDX]), s_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "        t_batch.append(torch.cat([torch.tensor([BOS_IDX]), t_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "        \n",
    "    s_batch = pad_sequence(s_batch, padding_value=PAD_IDX)\n",
    "    return s_batch.T, torch.stack(t_batch)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, collate_fn=generate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fa0bbff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s,t = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3c23a60e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 7]), torch.Size([16, 7]))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.shape, t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5b0f6d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([16, 7]) torch.Size([16, 7])\n",
      "1 torch.Size([16, 7]) torch.Size([16, 7])\n",
      "2 torch.Size([16, 7]) torch.Size([16, 7])\n",
      "3 torch.Size([16, 6]) torch.Size([16, 7])\n",
      "4 torch.Size([16, 7]) torch.Size([16, 7])\n",
      "5 torch.Size([16, 7]) torch.Size([16, 7])\n",
      "6 torch.Size([16, 7]) torch.Size([16, 7])\n",
      "7 torch.Size([16, 7]) torch.Size([16, 7])\n",
      "8 torch.Size([16, 6]) torch.Size([16, 7])\n",
      "9 torch.Size([16, 7]) torch.Size([16, 7])\n",
      "10 torch.Size([16, 7]) torch.Size([16, 7])\n",
      "11 torch.Size([16, 7]) torch.Size([16, 7])\n",
      "12 torch.Size([16, 6]) torch.Size([16, 7])\n",
      "13 torch.Size([16, 7]) torch.Size([16, 7])\n",
      "14 torch.Size([16, 7]) torch.Size([16, 7])\n",
      "15 torch.Size([16, 7]) torch.Size([16, 7])\n",
      "16 torch.Size([16, 7]) torch.Size([16, 7])\n"
     ]
    }
   ],
   "source": [
    "for i,each in enumerate(train_dataloader):\n",
    "    s, t = each\n",
    "    print(i,s.shape, t.shape)\n",
    "    if i > 15:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8dc9f5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, dropout_p=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.gru = nn.GRU(input_size=hidden_size, hidden_size=hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # input.shape = (N, Batch, Hidden)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6334c830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "703"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset.voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4aa8e447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 7, 64]), torch.Size([1, 16, 64]))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(train_dataset.voc)\n",
    "hidden_size = 64\n",
    "encoder = EncoderRNN(vocab_size, hidden_size)\n",
    "op = encoder(next(iter(train_dataloader))[0])\n",
    "op[0].shape, op[1].shape #(D*num_layers, N, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9b8d3072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 7, 703])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.MAX_LENGTH = 7\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(input_size=hidden_size, hidden_size=hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        target , encoder_op, _ = inputs\n",
    "        # target.shape = [B, L]\n",
    "        # encoder_op.shape = [1, B, H)]\n",
    "        \n",
    "        i = 0\n",
    "        decoder_logits= []\n",
    "        decoder_ip_h = encoder_op\n",
    "        decoder_ip_x = target[:,0]\n",
    "        for i in range(self.MAX_LENGTH):\n",
    "            \n",
    "            # forward step\n",
    "            decoder_ip_x = self.dropout(self.embedding(decoder_ip_x)) # [B, D]\n",
    "            decoder_ip_x = torch.unsqueeze(decoder_ip_x, dim=1) # [B, 1, D]\n",
    "            all_ops, op = self.gru(decoder_ip_x, decoder_ip_h) # [B, 1, H], [1, B, H]\n",
    "            op = torch.squeeze(op) # [B,H]\n",
    "            op = F.relu(op)\n",
    "            logits = self.linear(op) # [B, output_size]\n",
    "               \n",
    "            decoder_logits.append(logits)\n",
    "            \n",
    "            \n",
    "            decoder_ip_h = torch.permute(all_ops, (1,0,2)) # [1, B, H]  \n",
    "            _, decoder_ip_x = torch.max(logits, dim=-1) # [B,1]\n",
    "#             print(decoder_ip_x.shape, decoder_ip_h.shape)\n",
    "        \n",
    "        decoder_logits = torch.stack(decoder_logits, dim=1) # [B, 7, output_size]\n",
    "        log_probs = F.log_softmax(decoder_logits, dim=-1) \n",
    "        return log_probs, decoder_logits, None\n",
    "\n",
    "target = next(iter(train_dataloader))[1]\n",
    "encoder_op = op[1]\n",
    "inputs = (target, encoder_op, None)\n",
    "decoder = DecoderRNN(hidden_size, vocab_size)\n",
    "decoder_outputs, _ , _= decoder(inputs)\n",
    "decoder_outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "80b8ced1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([112, 703])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs.view(-1, decoder_outputs.size(-1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c1c71738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([144])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7a17e592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 9])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5ace37b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.001)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "437b83c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion):\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = decoder((target_tensor, encoder_hidden, encoder_outputs))\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.reshape(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7adcc4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.021697245650821"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9f29e8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 8, 6])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.permute(torch.ones(8,2,6),(1,0,2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5a398d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = train_dataset.voca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "009f3e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1924'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.get_itos()[do[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ae4a01c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(16, 1, dtype=torch.long).fill_(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f096b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch310]",
   "language": "python",
   "name": "conda-env-torch310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
